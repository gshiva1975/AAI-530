# -*- coding: utf-8 -*-
"""Cleaning & EDA Assignment .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G1WVEzArMONQ_Fkdjboz81_UsB9Qrn0c

# Data Cleaning and EDA with Time Series Data
This notebook holds Assignment 2.1 for Module 2 in AAI 530, Data Analytics and the Internet of Things.

In this assignment, you will go through some basic data cleaning and exploratory analysis steps on a real IoT dataset. Much of what we'll be doing should look familiar from Module 2's lab session, but Google will be your friend on the parts that are new.

## General Assignment Instructions

These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it.

One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link.

Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell.

When you save your notebook as a pdf, make sure that all cell output is visible (even error messages) as this will aid your instructor in grading your work.

Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a "Q:" and will have a corresponding "A:" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.*
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

#use this cell to import additional libraries or define helper functions
print(f'Data Cleaning and EDA Assignment')
print(f'Pandas version: {pd.__version__}')
print(f'Numpy version: {np.__version__}')

"""## Load and clean your data
The household electric consumption dataset can be downloaded as a zip file here along with a description of the data attributes:
https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption#

First we will load this data into a pandas df and do some initial discovery
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Read the file from Google Drive
df_raw = pd.read_csv('/content/drive/MyDrive/household_power_consumption.txt', delimiter=';')

df_raw.head()

df_raw.describe()

#Describe all columns
print(df_raw.describe(include='all'))

"""Well that's not what we want to see--why is only one column showing up?
Let's check the datatypes
"""

df_raw.dtypes

"""OK, so only one of our columns came in as the correct data type. We'll get to why that is later, but first let's get everything assigned correctly so that we can use our describe function.

**TODO: combine the 'Date' and 'Time' columns into a column called 'Datetime' and convert it into a datetime datatype. Heads up, the date is not in the standard format...**

**TODO: use the pd.to_numeric function to convert the rest of the columns. You'll need to decide what to do with your errors for the cells that don't convert to numbers**
"""

#make a copy of the raw data so that we can go back and refer to it later
df = df_raw.copy()

# Now Combine 'Date' and 'Time' columns into 'Datetime'
df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], format='%d/%m/%Y %H:%M:%S', errors='coerce')

# Drop the original 'Date' and 'Time' columns
df = df.drop(['Date', 'Time'], axis=1)

# Convert the rest of the columns to numeric, coercing errors to NaN
numeric_cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity',
                'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']
for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Print the data

df.head()

"""Let's use the Datetime column to turn the Date and Time columns into date and time dtypes."""

df['Date'] = df['Datetime'].dt.date
df['Time'] = df['Datetime'].dt.time

print(df['Time'])

print(df['Date'])

df.dtypes

"""It looks like our Date and Time columns are still of type "object", but in that case that's because the pandas dtypes function doesn't recognize all data types. We can check this by printing out the first value of each column directly."""

df.Date[0]

df.Time[0]

"""Now that we've got the data in the right datatypes, let's take a look at the describe() results"""

desc = df.describe()

#force the printout not to use scientific notation
desc[desc.columns[:-1]] = desc[desc.columns[:-1]].apply(lambda x: x.apply("{0:.4f}".format))
desc

"""Those row counts look a little funky. Let's visualize our missing data."""

df.isna().sum().plot.bar()

# Plot the important features
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from google.colab import drive


# Create subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 10))

# Plot 1: Global Active Power vs. Datetime
axes[0, 0].plot(df['Datetime'], df['Global_active_power'], color='blue')
axes[0, 0].set_title('Global Active Power over Time')
axes[0, 0].set_xlabel('Datetime')
axes[0, 0].set_ylabel('Global Active Power')

# Plot 2: Global Reactive Power vs. Datetime
axes[0, 1].plot(df['Datetime'], df['Global_reactive_power'], color='red')
axes[0, 1].set_title('Global Reactive Power over Time')
axes[0, 1].set_xlabel('Datetime')
axes[0, 1].set_ylabel('Global Reactive Power')

# Plot 3: Voltage vs. Datetime
axes[1, 0].plot(df['Datetime'], df['Voltage'], color='green')
axes[1, 0].set_title('Voltage over Time')
axes[1, 0].set_xlabel('Datetime')
axes[1, 0].set_ylabel('Voltage')

# Plot 4: Global Intensity vs. Datetime
axes[1, 1].plot(df['Datetime'], df['Global_intensity'], color='orange')
axes[1, 1].set_title('Global Intensity over Time')
axes[1, 1].set_xlabel('Datetime')
axes[1, 1].set_ylabel('Global Intensity')

# Adjust layout and display the plots
plt.tight_layout()
plt.show()

#https://stackoverflow.com/questions/53947196/groupby-class-and-count-missing-values-in-features
df_na = df.drop('Date', axis = 1).isna().groupby(df.Date, sort = False).sum().reset_index()
df_na.plot(x='Date', y=df_na.columns[2:-1])

"""**Q: What do you notice about the pattern of missing data?**

A:
The plot reveals that missing data is not randomly distributed across all the columns. Rather it seems to be clustered in bursts on certain days, rather than uniformly distributed. Some days have no missing data for the plotted features, while other days have a high concentration of missing data for all or most of the columns.  This indicates that there might be some systematic reason for the missing data, such as issues with the data collection process or sensor malfunction on specific dates, rather than simply random occurrences of missing values.

From the processed dataset, following missing data patterns is observed

**Random Missing Values:**

Some columns have sporadic missing values.

These missing values do not follow a strict pattern but appear intermittently.

**Gaps in Time-Series Data:**

If entire time periods (e.g., days) are missing.

**Column-Specific Missing Data:**

Certain columns, like Global_active_power or Sub_metering_1, 2, 3, may have more missing values than others.



**Effect on Analysis:**

Missing data can affect trend analysis and forecasting models.
If too much data is missing in a particular time period,

it may need imputation **(e.g., forward-fill, mean imputation, or interpolation**).


**Q: What method makes the most sense to you for dealing with our missing data and why? (There isn't necessarily a single right answer here)**

A: **1. Forward Fill (Propagation)**
Method: Replace missing values with the most recent available data.
Use Case: Works well for continuous time series data where values don’t change drastically (e.g., power consumption).
Pros: Maintains trend continuity.
Cons: Not ideal if there are long gaps, as it assumes no change.

**Interpolation (Linear, Polynomial, or Time-based)**
Method: Estimate missing values based on neighboring data points.
Use Case: Best for data with smooth trends, such as power consumption over time.
Pros: More accurate than forward fill, as it accounts for trends.
Cons: Can introduce errors if the data is highly volatile.

**Mean/Median Imputation**
Method: Replace missing values with the mean or median of the column.
Use Case: Best for columns with random missing values that don't depend on time.
Pros: Simple and effective for numerical features.
Cons: Not ideal for time-series data, as it ignores trends.

 **Dropping Missing Data**
Method: Remove rows or columns with missing values.
Use Case: Useful when missing data is minimal

**TODO:Use your preferred method to remove or impute a value for the missing data**
"""

#clean up missing data here

# Example using removal:
df.dropna(inplace=True) #Removes rows with any NaN values

desc = df.describe()

#force the printout not to use scientific notation
desc[desc.columns[:-1]] = desc[desc.columns[:-1]].apply(lambda x: x.apply("{0:.4f}".format))
desc

"""## Visualizing the data

We're working with time series data, so visualizing the data over time can be helpful in identifying possible patterns or metrics that should be explored with further analysis and machine learning methods.

**TODO: Choose four of the variables in the dataset to visualize over time and explore methods covered in our lab session to make a line chart of the cleaned data. Your charts should be separated by variable to make them more readable.**

**Q: Which variables did you choose and why do you think they might be interesting to compare to each other over time? Remember that data descriptions are available at the data source link at the top of the assignment.**

A:
 1.  **Global_active_power:** This is the total active power consumed by the household. It's a fundamental metric for energy consumption and serves as a baseline for understanding overall energy usage patterns over time.
 2.  **Global_reactive_power:** This represents the non-working power in the household's electrical system.  Comparing it to Global_active_power over time can reveal insights into the efficiency of energy usage. A higher reactive power relative to active power could indicate inefficiencies in the electrical system.
 3.  **Voltage:**  Voltage fluctuations can affect appliance performance and overall energy efficiency. Monitoring voltage over time helps to identify potential issues in the power supply.  Combining this with observations of active and reactive power could reveal how voltage changes affect energy usage.
 4.  **Global_intensity:** This is the current intensity in the household electrical system.  Changes in intensity, when viewed alongside voltage and active power, can provide information about the load on the household's electrical grid and potential correlations between these factors.

"""

import matplotlib.pyplot as plt

# it has a 'Datetime' column
# and the four columns you selected: 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity'

# Create subplots
fig, axes = plt.subplots(4, 1, figsize=(15, 20))

# Plot 1: Global Active Power vs. Datetime
axes[0].plot(df['Datetime'], df['Global_active_power'],color='orange')
axes[0].set_title('Global Active Power over Time')
axes[0].set_xlabel('Datetime')
axes[0].set_ylabel('Global Active Power')

# Plot 2: Global Reactive Power vs. Datetime
axes[1].plot(df['Datetime'], df['Global_reactive_power'],color='red')
axes[1].set_title('Global Reactive Power over Time')
axes[1].set_xlabel('Datetime')
axes[1].set_ylabel('Global Reactive Power')

# Plot 3: Voltage vs. Datetime
axes[2].plot(df['Datetime'], df['Voltage'],color='green')
axes[2].set_title('Voltage over Time')
axes[2].set_xlabel('Datetime')
axes[2].set_ylabel('Voltage')

# Plot 4: Global Intensity vs. Datetime
axes[3].plot(df['Datetime'], df['Global_intensity'],color='pink')
axes[3].set_title('Global Intensity over Time')
axes[3].set_xlabel('Datetime')
axes[3].set_ylabel('Global Intensity')

# Adjust layout and display the plots
plt.tight_layout()
plt.show()

#  Daily and Weekly Cycles: for 1 month

import pandas as pd
import matplotlib.pyplot as plt


# If not, load your data and create the 'df' DataFrame here

# Filter data for one month (e.g., January 2007)
# Adjust the start and end dates as needed
start_date = '2007-01-01'
end_date = '2007-01-31'

df_month = df[(df['Datetime'] >= start_date) & (df['Datetime'] <= end_date)]



daily_data = df_month.resample('D', on='Datetime')[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].mean()

# Resample to weekly frequency and calculate the mean
# Exclude the 'Date' column from the mean calculation
weekly_data = df_month.resample('W', on='Datetime')[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].mean()



# Create the plots
fig, axes = plt.subplots(2, 1, figsize=(12, 8))

# Daily Cycle
axes[0].plot(daily_data.index, daily_data['Global_active_power'])  # Example: Plot Global_active_power
axes[0].set_title('Daily Cycle of Global Active Power')
axes[0].set_xlabel('Date')
axes[0].set_ylabel('Mean Global Active Power')

# Weekly Cycle
axes[1].plot(weekly_data.index, weekly_data['Global_active_power'])  # Example: Plot Global_active_power
axes[1].set_title('Weekly Cycle of Global Active Power')
axes[1].set_xlabel('Date')
axes[1].set_ylabel('Mean Global Active Power')

plt.tight_layout()
plt.show()

# Filter data for one month (e.g., January 2007)
# Adjust the start and end dates as needed
start_date = '2007-01-01'
end_date = '2007-01-31'

df_month = df[(df['Datetime'] >= start_date) & (df['Datetime'] <= end_date)]



daily_data = df_month.resample('D', on='Datetime')[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].mean()

# Resample to weekly frequency and calculate the mean
# Exclude the 'Date' column from the mean calculation
weekly_data = df_month.resample('W', on='Datetime')[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].mean()

print("daily data\n")
print(daily_data)

print("\n weekly data\n")
print(weekly_data)

import pandas as pd



# Specify the start and end dates for the 10-day period
start_date = '2007-01-01'  # Replace with your desired start date
end_date = '2007-01-10'  # Replace with your desired end date


df_10_days = df[(df['Datetime'] >= start_date) & (df['Datetime'] <= end_date)]

df_10_days

"""**Q: What do you notice about visualizing the raw data? Is this a useful visualization? Why or why not?**


A: Visualizing the raw data as time series plots reveals several key characteristics:

1.  **Noisy Data:** The raw data exhibits a high degree of noise and short-term fluctuations. This makes it challenging to discern underlying trends or patterns directly.

2.  **Daily and Weekly Cycles:** There appear to be discernible daily and potentially weekly cycles in the data, especially for global active power.   Weekly patterns could reflect differences in weekday vs. weekend usage.

3.  **Overall Trend (Less Clear):**  While daily and weekly patterns are apparent, it is difficult to observe any long-term trend from the raw data visualizations. The noise obscures the longer-term behavior of energy consumption.

4.  **Missing Data Impact:** The missing data gaps also affect visual interpretation, making it hard to see trends that may have been present in the missing periods.

Because of the inherent noise in the data and the presence of daily and weekly cycles, visualizing raw data alone is not very useful for identifying broader trends or long-term patterns in energy consumption.  Aggregating the data (as is done with monthly averages in the next step) is necessary to reduce noise and clearly reveal underlying trends.  The raw data visualization serves mainly as a first step to understand the data's characteristics before further analysis or aggregation is done.

**TODO: Compute a monthly average for the data and plot that data in the same style as above. You should have one average per month and year (so June 2007 is separate from June 2008).**
"""

#compute your monthly average here
#HINT: checkout the pd.Grouper function: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Grouper.html?highlight=grouper

# Group data by month and year and calculate the mean for each group, excluding the 'Date' and 'Time' columns
#The Date and Time columns cause errors when calculating the mean, and are not useful for this analysis
monthly_average = df.drop(columns=['Date','Time']).groupby(pd.Grouper(key='Datetime', freq='M')).mean()

# Choose four variables to visualize
variables_to_plot = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']

# Create subplots for each variable
fig, axes = plt.subplots(len(variables_to_plot), 1, figsize=(15, 5 * len(variables_to_plot)))

# Iterate through the selected variables and plot the monthly averages
for i, variable in enumerate(variables_to_plot):
    axes[i].plot(monthly_average.index, monthly_average[variable],color='orange')
    axes[i].set_title(f'Monthly Average of {variable} Over Time')
    axes[i].set_xlabel('Month and Year')
    axes[i].set_ylabel(variable)
    axes[i].grid(True)

plt.tight_layout()
plt.show()

#the four columns selected: 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity'

# Create a single panel plot for monthly average data
plt.figure(figsize=(15, 8))

plt.plot(monthly_average.index, monthly_average['Global_active_power'], label='Global Active Power')
plt.plot(monthly_average.index, monthly_average['Global_reactive_power'], label='Global Reactive Power')
plt.plot(monthly_average.index, monthly_average['Voltage'], label='Voltage')
plt.plot(monthly_average.index, monthly_average['Global_intensity'], label='Global Intensity')

plt.title('Monthly Average of Global Intensity, Voltage, Active Power, and Reactive Power Over Time')
plt.xlabel('Month and Year')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability
plt.tight_layout()
plt.show()

# Group data by month and year and calculate the mean for each group, excluding the 'Date' and 'Time' columns
#The Date and Time columns cause errors when calculating the mean, and are not useful for this analysis
monthly_average = df.drop(columns=['Date','Time']).groupby(pd.Grouper(key='Datetime', freq='ME')).mean()

print(monthly_average)

# and the four columns you selected: 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity'

# Create subplots
fig, axes = plt.subplots(4, 1, figsize=(15, 20))

# Plot 1: Global Active Power vs. Datetime
axes[0].plot(df['Datetime'], df['Global_active_power'],color='orange')
axes[0].set_title('Global Active Power over Time')
axes[0].set_xlabel('Datetime')
axes[0].set_ylabel('Global Active Power')

# Plot 2: Global Reactive Power vs. Datetime
axes[1].plot(df['Datetime'], df['Global_reactive_power'],color='orange')
axes[1].set_title('Global Reactive Power over Time')
axes[1].set_xlabel('Datetime')
axes[1].set_ylabel('Global Reactive Power')

# Plot 3: Voltage vs. Datetime
axes[2].plot(df['Datetime'], df['Voltage'],color='orange')
axes[2].set_title('Voltage over Time')
axes[2].set_xlabel('Datetime')
axes[2].set_ylabel('Voltage')

# Plot 4: Global Intensity vs. Datetime
axes[3].plot(df['Datetime'], df['Global_intensity'],color='orange')
axes[3].set_title('Global Intensity over Time')
axes[3].set_xlabel('Datetime')
axes[3].set_ylabel('Global Intensity')

# Adjust layout and display the plots
plt.tight_layout()
plt.show()

"""**Q: What patterns do you see in the monthly data? Do any of the variables seem to move together?**

A:

From the monthly resampled data and correlation matrix, we observe the following:

1. Identified Patterns in Monthly Trends
Global Active Power & Global Intensity show a strong similarity in their monthly trends.
Voltage is relatively stable but exhibits minor fluctuations.
Global Reactive Power has an inverse relationship with Global Active Power.
**TODO: Now compute a 30-day moving average on the original data and visualize it in the same style as above. Hint: If you use the rolling() function, be sure to consider the resolution of our data.**


Smoother Trends:
The moving average removes short-term fluctuations, making long-term patterns more visible.
Lagging Effect:
The moving average introduces a lag in the data, as it is based on past values.
Better Visibility of Seasonal Changes:
Helps in identifying gradual increases or decreases over time.

**Moving Average**

Example: 30-Day Simple Moving Average
Let's say we want to calculate the 30-day SMA for a stock on day 30. We'll use the closing prices for the last 30 days.

Given Data:

Day 1 (oldest): $100

Day 2: $102

Day 3: $101

...

Day 28: $105

Day 29: $106

Day 30 (most recent): $104

**Formula:**

SMA₃₀ = (X₃₀ + X₂₉ + X₂₈ + ... + X₂ + X₁) / 30
Where X₃₀ is the price on day 30, X₂₉ is the price on day 29, and so on.

**Calculation:**
Let's assume the sum of all 30 days' prices is $3,120.
SMA₃₀ = $3,120 / 30 = $104

**Interpretation:**
The 30-day Simple Moving Average is $104. This means that, on average, the stock price over the last 30 days was $104.

**Moving to the Next Day:**
On day 31, we would drop the oldest price (from day 1) and add the new price from day 31. Then we'd recalculate the average using the same formula.
This example demonstrates how the SMA "moves" by continuously updating with new data while maintaining a consistent look-back period of 30 days.
"""

# Calculate a 30-day rolling mean for selected variables
variables_to_plot = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']
rolling_mean_30d = df[variables_to_plot].rolling(window=2880, min_periods=1).mean() # 2880 data points per 30 days (24 hours * 60 minutes / 10 minutes)

# Create subplots for each variable
fig, axes = plt.subplots(len(variables_to_plot), 1, figsize=(15, 5 * len(variables_to_plot)))

# Iterate through the selected variables and plot the 30-day rolling means
for i, variable in enumerate(variables_to_plot):
    axes[i].plot(df['Datetime'], rolling_mean_30d[variable], label='30-Day Rolling Mean')
    axes[i].plot(df['Datetime'], df[variable], alpha=0.5, label='Original Data')  # Plot original data for comparison
    axes[i].set_title(f'30-Day Rolling Mean of {variable} Over Time')
    axes[i].set_xlabel('Datetime')
    axes[i].set_ylabel(variable)
    axes[i].legend()  # Add legend to differentiate the lines
    axes[i].grid(True)

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt



# Calculate a 30-day rolling mean for selected variables
variables_to_plot = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']
rolling_mean_30d = df[variables_to_plot].rolling(window=2880, min_periods=1).mean() # 2880 data points per 30 days (24 hours * 60 minutes / 10 minutes)

print(rolling_mean_30d)

# Calculate the 30-day moving average, excluding the 'Datetime' column
moving_average_30d = df.drop(columns=['Date','Time', 'Datetime']).rolling(window=48*30, min_periods=1).mean() # 48 readings per day

# Choose four variables to visualize
variables_to_plot = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']

# Create subplots for each variable
fig, axes = plt.subplots(len(variables_to_plot), 1, figsize=(15, 5 * len(variables_to_plot)))

# Iterate through the selected variables and plot the 30-day moving averages
for i, variable in enumerate(variables_to_plot):
    axes[i].plot(df['Datetime'], moving_average_30d[variable],color='pink')
    axes[i].set_title(f'30-Day Moving Average of {variable} Over Time')
    axes[i].set_xlabel('Datetime')
    axes[i].set_ylabel(variable)
    axes[i].grid(True)

plt.tight_layout()
plt.show()

"""**Q: How does the moving average compare to the monthly average? Which is a more effective way to visualize this data and why?**


A: The moving average and monthly average both smooth out the noise in the original time series data, making underlying trends more apparent. However, they offer different perspectives:
#
 *   **Moving Average:** Provides a more localized view of trends.  A 30-day moving average highlights short-term fluctuations and changes in the data over a shorter period. It's excellent for spotting recent shifts or patterns within a month.
 *   **Monthly Average:** Offers a broader, more summarized view of trends over longer time intervals. It emphasizes seasonal or cyclical patterns that span an entire month. It's less sensitive to day-to-day variations but better for identifying longer-term changes or seasonality.

**Which is more effective?**

**It depends on the analytical goal.**

 *   For detecting recent changes or short-term trends, the **30-day moving average** is generally more informative.
 *   For understanding long-term seasonality or yearly cycles, the **monthly average** is a better choice.

 In some cases, visualizing **both** the moving average and the monthly average on the same plot can provide a comprehensive view of the data, showing both short-term and long-term patterns simultaneously.


## Data Covariance and Correlation

Let's take a look at the Correlation Matrix for the four global power variables in the dataset.
"""

# ## Data Covariance and Correlation
#
# Let's take a look at the Correlation Matrix for the four global power variables in the dataset.


variables = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']
correlation_matrix = df[variables].corr()
print(correlation_matrix)

import seaborn as sns
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='viridis', fmt=".2f")
plt.title('Correlation Matrix of Global Power Variables')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np


# (e.g., 'Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity')

# Instead of a fixed color palette, use a colormap to generate colors based on data values
# For example, you can use 'viridis' colormap:
cmap = 'viridis'

# Create the scatter plot matrix with the colormap
axes = pd.plotting.scatter_matrix(
    df[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']],
    alpha=0.5,
    figsize=[10, 10],
    c=df['Global_active_power'],  # Use a column for color mapping
    cmap=cmap  # Apply the colormap
)

corr = df[['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']].corr(method='spearman').to_numpy()  # nonlinear
for i, j in zip(*plt.np.triu_indices_from(axes, k=1)):
    axes[i, j].annotate("%.3f" % corr[i, j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center')
plt.show()

def detect_anomalies(df, column_name, threshold=3):


    Q1 = df[column_name].quantile(0.25)
    Q3 = df[column_name].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - threshold * IQR
    upper_bound = Q3 + threshold * IQR

    return ~df[column_name].between(lower_bound, upper_bound)


# Example usage:
variables = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity']

for variable in variables:
    df[f'{variable}_anomaly'] = detect_anomalies(df, variable)


# Display the DataFrame with the anomaly flags
print(df)

# Visualize the anomalies (example for 'Global_active_power')
plt.figure(figsize=(15, 6))
plt.plot(df['Datetime'], df['Global_active_power'], label='Global Active Power')
plt.scatter(df['Datetime'][df['Global_active_power_anomaly']], df['Global_active_power'][df['Global_active_power_anomaly']], color='red', label='Anomalies')

plt.title('Global Active Power with Anomalies Highlighted')
plt.xlabel('Datetime')
plt.ylabel('Global Active Power')
plt.legend()
plt.show()

"""**Q: Describe any patterns and correlations that you see in the data. What effect does this have on how we use this data in downstream tasks?**

A:
From the moving average, monthly trends, and correlation analysis, we can identify several key patterns:

**1. Seasonal and Daily Trends**
Global Active Power shows periodic fluctuations:

Higher values during peak hours (morning & evening).
Possible seasonal variations across months.
Voltage remains relatively stable:

Small fluctuations but no strong seasonal effect.
Global Intensity and Active Power are highly correlated:

Higher power usage results in higher current draw.
Reactive Power moves inversely to Active Power:

When active power is high, reactive power tends to be lower.
**2. Strong Correlations**
Variable Pair	Correlation	Interpretation
Global Active Power & Global Intensity	0.999	Almost perfectly correlated—intensity increases with power usage.

Global Active Power & Voltage	0.406	Weak correlation, indicating voltage does not significantly fluctuate with power usage.

Global Active Power & Global Reactive Power	-0.494	Inversely related, showing the trade-off between active and reactive power.
Impact on Downstream Tasks

**Forecasting & Energy Demand Planning:**

The strong correlation between Global Active Power and Intensity allows accurate forecasting.
Moving averages and seasonal trends help in predicting peak consumption hours.

 **Anomaly Detection & Outlier Analysis:**

Sudden drops or spikes in voltage or power usage may indicate equipment failure or energy theft.
Comparing **moving averages to real-time data** helps detect unexpected fluctuations.

"""

#







#










#











#








#

#







#








#












#

#











#










#















#














#.   The End

#


















#










#

#




















#

#













#

#




















#